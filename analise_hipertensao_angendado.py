# -*- coding: utf-8 -*-
"""ANALISE_HIPERTENSAO_ANGENDADO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1In_C0fQLYn2-i6oc8GtEknZ4i6Z6KVYa

# **NOVACK RENATO BORGES**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**Projeto de Ciência de Dados**

Qual propabilidade de pessoas agendadas possuirem hipertensão?

### **Importar as bibliotecas**
"""

# Commented out IPython magic to ensure Python compatibility.

import pandas as pd 
import numpy as np
import matplotlib as mat
import matplotlib.pyplot as plt
import joblib
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler 
from sklearn.model_selection import train_test_split 
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.neural_network import MLPClassifier
# Método para avaliar a acurácia dos modelos
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score 
# %matplotlib inline

"""### **Processamento, Tratamento e Análise Exploratória dos Dados**"""

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/KaggleV2-May-2016.csv')

# conhecer o formato do nosso dataframe
df.shape

"""**Dicionário de Dados:**



*   Genero: Masculo (M) Feminino (F)
*   Dia do agendamento: Dia da solicitação de atendimento
*   Dia agendado: Dia agendado para consulta
*   Idade: Idade do paciente
*   Bairro: Bairro onde mora
*   Bolsade Estudods: Classificação (0 ou 1 - 0 não / 1 sim)
*   Hipertensão: Classificação (0 ou 1 - 0 não é hipertenso / 1 é hipertenso)
*   Diabetes: Classificação (0 ou 1 - 0 não diabético / 1 diabético )
*   Alcolismo: Classificação (0 ou 1 - 0 não / 1 sim)
*   Deficiancia: Classificação (0 ou 1 - 0 não / 1  sim)

"""

# Queremos entender as primeiras linhas do nosso df
# Podemos escolher a quantidade de linhas que queremos ver
# Observe a quantidade de colunas que nosso df possui
# head = cabeça (primeiras linhas do df)
df.head()

# Também podemos investigar quais são os valores das últimas linhas do nosso df
# head = rabo (últimas linhas do df)
df.tail()

df.columns

df.isnull().values.any()

# Informações gerais sobre o df
df.info()

# describe = medidas estatísticas básicas do df
df.describe()

# Quantidade de casos de Diabetes (outcomes)
df['Hipertensao'].value_counts()

# Usar a biblioteca SWEETVIZ para fazer EDA
# Para instalar o pacote sweetviz
!pip install sweetviz
# Importando o pacote
import sweetviz as sv
#Utilizando
analise = sv.analyze(df)
analise.show_html('Hipertensao.html')

def plot_corr(df, size=7):
  corr= df.corr()
  fig, ax = plt.subplots(figsize=(size, size))
  ax.matshow(corr)
  plt.xticks(range(len(corr.columns)), corr.columns)
  plt.yticks(range(len(corr.columns)), corr.columns)

plot_corr(df)

df.corr()

# Outra maneira de avaliar a coorelação entre as variáveis
import seaborn as sns
sns.set(color_codes=True)
cor=df.corr()
cor

# Matriz de Correlação
sns.heatmap(cor,annot=True)

num_true = len(df.loc[df['Hipertensao'] == True])
num_false = len(df.loc[df['Hipertensao'] == False])
print("Número de Casos Verdadeiros: {0} ({1:2.2f}%)".format(num_true, (num_true/ (num_true + num_false)) * 100))
print("Número de Casos Falsos     : {0} ({1:2.2f}%)".format(num_false, (num_false/ (num_true + num_false)) * 100))

"""### **Dividir o Banco de Dados**

Para melhorar a análise, vamos dividir nosso banco de dados em 2: 

1.   Banco de dados de treino
2.   Banco de dados de teste
"""

import sklearn as sk
sk.__version__

from sklearn.model_selection import train_test_split

atributos = ['PacienteId', 'EncontroID',
       'Idade', 'BolsadeEstudos', 'Hipertensao', 'Diabetes',
       'Alcolismo', 'Deficiencia', 'SMS_recebido']

atributos_prev= ['Hipertensao']

X = df[atributos].values
y = df[atributos_prev].values

X

y

split_test_size = 0.20

from sklearn.model_selection import train_test_split

X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, y, test_size = split_test_size, random_state = 42)

print("{0:0.2f}% nos dados de treino".format((len(X_treino)/len(df.index)) * 100))
print("{0:0.2f}% nos dados de teste".format((len(X_teste)/len(df.index)) * 100))

X_treino

"""### **Verificar o split dos dados**"""

print("Original True : {0} ({1:0.2f}%)".format(len(df.loc[df['Hipertensao'] == 1]), 
                                               (len(df.loc[df['Hipertensao'] ==1])/len(df.index) * 100)))

print("Original False : {0} ({1:0.2f}%)".format(len(df.loc[df['Hipertensao'] == 0]), 
                                               (len(df.loc[df['Hipertensao'] == 0])/len(df.index) * 100)))
print("")
print("Training True : {0} ({1:0.2f}%)".format(len(Y_treino[Y_treino[:] == 1]), 
                                               (len(Y_treino[Y_treino[:] == 1])/len(Y_treino) * 100)))

print("Training False : {0} ({1:0.2f}%)".format(len(Y_treino[Y_treino[:] == 0]), 
                                               (len(Y_treino[Y_treino[:] == 0])/len(Y_treino) * 100)))
print("")
print("Test True : {0} ({1:0.2f}%)".format(len(Y_teste[Y_teste[:] == 1]), 
                                               (len(Y_teste[Y_teste[:] == 1])/len(Y_teste) * 100)))

print("Test False : {0} ({1:0.2f}%)".format(len(Y_teste[Y_teste[:] == 0]), 
                                               (len(Y_teste[Y_teste[:] == 0])/len(Y_teste) * 100)))

"""### **Valores Missing Ocultos**"""

df.isnull().values.any()

print("# Linhas no dataframe {0}".format(len(df)))
print("# Linhas missing Idade: {0}".format(len(df.loc[df['Idade'] == 0])))
print("# Linhas missing Diabetes: {0}".format(len(df.loc[df['Diabetes'] == 0])))
print("# Linhas missing Alcolismo: {0}".format(len(df.loc[df['Alcolismo'] == 0])))
print("# Linhas missing Deficiencia: {0}".format(len(df.loc[df['Deficiencia'] == 0])))
print("# Linhas missing SMS: {0}".format(len(df.loc[df['SMS_recebido'] == 0])))

"""### **Tratando dados missing**

Imputação de dados: substituindo os valores zerados pela média dos dados.
"""

from sklearn.impute import SimpleImputer

preenche_0 = SimpleImputer(missing_values = 0, strategy = "mean")
X_treino = preenche_0.fit_transform(X_treino)
X_teste = preenche_0.fit_transform(X_teste)

X_treino

"""# **Resultados**

### **Modelo de Regressão Logística**
"""

# implementar o modelo
modelo_lr = LogisticRegression(C = 0.7, random_state = 42, max_iter = 1000)
modelo_lr.fit(X_treino, Y_treino.ravel())
y_forecast_lr = modelo_lr.predict(X_teste)

print(f'Acurácia do Modelo de Regressão Logística: {accuracy_score(Y_teste, y_forecast_lr)*100}')
print()
print("Classification Report")
print(metrics.classification_report(Y_teste, y_forecast_lr, labels = [1, 0]))

"""### **Multilayer Perceptron (MLP)**"""

# Building MLP model
modelo_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 10), random_state=1)

# Training MLP model
modelo_mlp.fit(X_treino, Y_treino)

# Testing MLP model
y_forecast_mlp = modelo_mlp.predict(X_teste)

print(f'Acurácia do Modelo de Regressão Logística: {accuracy_score(Y_teste, y_forecast_mlp)*100}')
print()
print("Classification Report")
print(metrics.classification_report(Y_teste, y_forecast_mlp, labels = [1, 0]))

"""### **KNN (K nearest neighbor)**"""

# Building KNN model with 5 neighbors (K=5)
modelo_KNN = KNeighborsClassifier(n_neighbors=5)

# Training the KNN model
modelo_KNN.fit(X_treino, Y_treino)

# Testing the KNN model
y_forecast_KNN = modelo_KNN.predict(X_teste)

print("Exatidão (Accuracy): {0:.4f}".format(metrics.accuracy_score(Y_teste, y_forecast_KNN)))
print()
print("Classification Report")
print(metrics.classification_report(Y_teste, y_forecast_KNN, labels = [1, 0]))

"""### **Decision Tree**"""

# Building Tree model 
modelo_tree = DecisionTreeClassifier(random_state=1)

# Training the Tree model
modelo_tree.fit(X_treino, Y_treino)

# Testing the Tree model
y_forecast_tree = modelo_tree.predict(X_teste)

print("Exatidão (Accuracy): {0:.4f}".format(metrics.accuracy_score(Y_teste, y_forecast_tree)))
print()
print("Classification Report")
print(metrics.classification_report(Y_teste, y_forecast_tree, labels = [1, 0]))

"""### **Classificador Naive Bayes**"""

# Utilizando um classificador Naive Bayes
from sklearn.naive_bayes import GaussianNB

# Criando o modelo preditivo
modelo_NB = GaussianNB()

# Treinando o modelo
modelo_NB.fit(X_treino, Y_treino.ravel())

from sklearn import metrics
y_forecast_NB = modelo_NB.predict(X_teste)
print("Exatidão (Accuracy): {0:.4f}".format(metrics.accuracy_score(Y_teste, y_forecast_NB)))
print()
print("Classification Report")
print(metrics.classification_report(Y_teste, y_forecast_NB, labels = [1, 0]))

"""### **Comparando a acurácia (exatidão) dos modelos**"""

# Comparing models accuracy
print(f'Acurácia do Modelo MLP: {accuracy_score(Y_teste, y_forecast_mlp)*100}')
print(f'Acurácia do Modelo KNN: {accuracy_score(Y_teste, y_forecast_KNN)*100}')
print(f'Acurácia do Modelo Decision Tree: {accuracy_score(Y_teste, y_forecast_tree)*100}')
print(f'Acurácia do Modelo NB: {accuracy_score(Y_teste, y_forecast_NB)*100}')
print(f'Acurácia do Modelo de Regressão Logística: {accuracy_score(Y_teste, y_forecast_lr)*100}')

"""### **Previsões com o modelo treinado!**"""

import pickle

filename = 'modelo_lr_treinado.sav'
pickle.dump(y_forecast_lr, open(filename, 'wb'))

X_teste